{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n",
    "pip install azure-cognitiveservices-vision-customvision\n",
    "pip install azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import io\n",
    "import math\n",
    "import DataPrep\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry,ImageFileCreateBatch,Region\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from sklearn import preprocessing\n",
    "from DataPrep import BuildCoordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding subscription key and endpoints\n",
    "training_endpoint = \"https://csvsc1task4point2d.cognitiveservices.azure.com/\"\n",
    "training_key=\"\"\n",
    "prediction_key=\"\"\n",
    "prediction_endpoint = \"https://csvsc1task4point2d-prediction.cognitiveservices.azure.com/\"\n",
    "prediction_resource_id=\"/subscriptions/be831466-57b1-483b-91b7-a81607321d1e/resourceGroups/RGTask4Point2SC1/providers/Microsoft.CognitiveServices/accounts/CSVSC1Task4Point2D-Prediction\"\n",
    "publish_iteration_name = \"Iteration5\"\n",
    "# trainer = CustomVisionTrainingClient(training_key,training_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I have created an instance of the CustomVision training and prediction clients\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(training_endpoint, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(prediction_endpoint, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "#Creating new project on custom vision\n",
    "print(\"Creating project...\")\n",
    "project = trainer.create_project(\"CSVProj1Task4Point2\",domain_id = obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = trainer.get_project('87c97806-1dee-489a-a52b-6881edc9b760',None,False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making tags in the new project\n",
    "bikes_tag = trainer.create_tag(project.id,\"bike\")\n",
    "buses_tag = trainer.create_tag(project.id,\"bus\")\n",
    "cars_tag = trainer.create_tag(project.id,\"car\")\n",
    "autorickshaw_tag = trainer.create_tag(project.id,\"autorickshaw\")\n",
    "truck_tag = trainer.create_tag(project.id,\"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to get co-ordinates from training images. Here I am defining the variables which will hold the co-ordinates of the images\n",
    "bikes_regions= {}\n",
    "cars_regions = {}\n",
    "buses_regions = {}\n",
    "autorickshaw_regions = {}\n",
    "truck_regions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method calls the DataPrep library and executes the BuildCoordinates() method of the library. Json files with each vehicle category \n",
    "#will be created on running this cell. \n",
    "#Each json file contains the co-ordinates of all images of that category. \n",
    "DataPrep.BuildCoordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This piece of code reads the json files created above and reads the files and writes them into dictionaries of each vehicle category.\n",
    "json_dir = \"C:/Applications/Machine Learning/MDS-Data Science/mds-deakin/Object Detection using CustomVision/json/\" \n",
    "\n",
    "for file in os.listdir(json_dir):\n",
    "    with open(os.path.join(json_dir, file),mode='rb') as f:\n",
    "        if os.path.splitext(os.path.basename(file))[0] == \"bus\":\n",
    "            buses_regions = json.load(f)\n",
    "        elif os.path.splitext(os.path.basename(file))[0] == \"car\":\n",
    "            cars_regions = json.load(f)\n",
    "        elif os.path.splitext(os.path.basename(file))[0] == \"bike\":\n",
    "            bikes_regions = json.load(f)\n",
    "        elif os.path.splitext(os.path.basename(file))[0] == \"autorickshaw\":\n",
    "            autorickshaw_regions = json.load(f)\n",
    "        elif os.path.splitext(os.path.basename(file))[0] == \"truck\":\n",
    "            truck_regions = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will tag each image and upload it to the Azure Custom Vision project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag images and upload them\n",
    "training_folder = \"C:/Applications/Machine Learning/MDS-Data Science/mds-deakin/Object Detection using CustomVision/Dataset/mini_vehicle_dataset/train\"\n",
    "base_image_location = training_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the data table above and create the images\n",
    "print (\"Adding images...\")\n",
    "tagged_images_with_regions = []\n",
    "\n",
    "\n",
    "for file_name in buses_regions.keys():\n",
    "    x,y,w,h = buses_regions[file_name]\n",
    "    arr = np.array([x,y,w,h])\n",
    "    print(arr)\n",
    "    #Here, the actual coordinates have been converted to the normalized coordinates using the sklearn library.\n",
    "    normalized_corr= preprocessing.normalize([arr])\n",
    "    print(normalized_corr)\n",
    "    bu_regions = [ Region(tag_id=buses_tag.id, left=normalized_corr[0][0],top=normalized_corr[0][1],width=normalized_corr[0][2],height=normalized_corr[0][3]) ]\n",
    "    #Here Images are being labelled using the tags and created using the below line.\n",
    "    with open(base_image_location +\"/buses/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=bu_regions))\n",
    "\n",
    "\n",
    "for file_name in cars_regions.keys():\n",
    "    x,y,w,h = cars_regions[file_name]\n",
    "    arr = np.array([x,y,w,h])\n",
    "    print(arr)\n",
    "    normalized_corr= preprocessing.normalize([arr])\n",
    "    print(normalized_corr)\n",
    "    c_regions = [ Region(tag_id=cars_tag.id, left=normalized_corr[0][0],top=normalized_corr[0][1],width=normalized_corr[0][2],height=normalized_corr[0][3]) ]\n",
    "\n",
    "    with open(base_image_location +\"/cars/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=c_regions))\n",
    "\n",
    "for file_name in bikes_regions.keys():\n",
    "    x,y,w,h = bikes_regions[file_name]\n",
    "    arr = np.array([x,y,w,h])\n",
    "    print(arr)\n",
    "    normalized_corr= preprocessing.normalize([arr])\n",
    "    print(normalized_corr)\n",
    "    bi_regions = [ Region(tag_id=bikes_tag.id, left=normalized_corr[0][0],top=normalized_corr[0][1],width=normalized_corr[0][2],height=normalized_corr[0][3]) ]\n",
    "\n",
    "    with open(base_image_location +\"/bikes/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=bi_regions))\n",
    "\n",
    "for file_name in autorickshaw_regions.keys():\n",
    "    x,y,w,h = autorickshaw_regions[file_name]\n",
    "    arr = np.array([x,y,w,h])\n",
    "    print(arr)\n",
    "    normalized_corr= preprocessing.normalize([arr])\n",
    "    print(normalized_corr)\n",
    "    ar_regions = [ Region(tag_id=autorickshaw_tag.id, left=normalized_corr[0][0],top=normalized_corr[0][1],width=normalized_corr[0][2],height=normalized_corr[0][3]) ]\n",
    "\n",
    "    with open(base_image_location +\"/autorickshaw/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=ar_regions))\n",
    "\n",
    "for file_name in truck_regions.keys():\n",
    "    x,y,w,h = truck_regions[file_name]\n",
    "    arr = np.array([x,y,w,h])\n",
    "    print(arr)\n",
    "    normalized_corr= preprocessing.normalize([arr])\n",
    "    print(normalized_corr)\n",
    "    tr_regions = [ Region(tag_id=truck_tag.id, left=normalized_corr[0][0],top=normalized_corr[0][1],width=normalized_corr[0][2],height=normalized_corr[0][3]) ]\n",
    "\n",
    "    with open(base_image_location +\"/trucks/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=tr_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the below piece of code, I have set the upper limit of uploading images to 64. The total number of batches is calculated using the math.ceil method. \n",
    "#Now, each batch is iterated over to upload the images in the Azure Custom Vision training project.\n",
    "upper_limit = 64\n",
    "batch_count = math.ceil(len(tagged_images_with_regions)/upper_limit)\n",
    "print(batch_count)\n",
    "#Iterate over each batch\n",
    "for i in range(batch_count):\n",
    "    start = i * upper_limit\n",
    "    end = min((i+1)*upper_limit,len(tagged_images_with_regions))\n",
    "    tagged_images = tagged_images_with_regions[start:end]\n",
    "    print(len(tagged_images))\n",
    "    \n",
    "    #Finally, upload the images of the current batch to Azure CustomVision project        \n",
    "    upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images))\n",
    "    if not upload_result.is_batch_successful:\n",
    "        print(\"Image batch upload failed.\")\n",
    "        for image in upload_result.images:\n",
    "            print(\"Image status: \", image.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images_with_regions))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    #exit(-1) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am training the model using the train_project API. Once trained the project is published\n",
    "print(\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while(iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id,iteration.id)\n",
    "    print(\"Training status: \" + iteration.status)\n",
    "\n",
    "#the iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id,iteration.id,publish_iteration_name,prediction_resource_id)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model using an actual traffic video and check if vehicles are being detected using the tags we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I have captured the video using OpenCV videocapture class\n",
    "cap=cv2.VideoCapture(\"./Dataset/traffic.mp4/input videos/unlabelled_traffic2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I \n",
    "print(\"Frame count of video: \",int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(\"Number of frames per second of video: \",int(cap.get(cv2.CAP_PROP_FPS)))\n",
    "# Get the video width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(\"Width of video is {frame_width} and height of video is {frame_height} \",frame_width,frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the frame rate to 1 frame per second\n",
    "frame_rate = 1\n",
    "frame_count = 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below piece of code, I am iterating through each frame and passing the frame to the \"detect_image\" API at 1 frame per second. Next I am drawing a bounding box on the frame and displaying the tag along with the confidence percent and saving the frame as an image on my local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through each frame in the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Here I am sending only frame per second to the Custom Vision Service\n",
    "    if frame_count % frame_rate == 0:\n",
    "        \n",
    "        # Converting the frame to a byte array and sending it to the Custom Vision Service\n",
    "        _, img_encoded = cv2.imencode('.jpg', frame)\n",
    "        results = predictor.detect_image(project.id, publish_iteration_name, img_encoded.tobytes())\n",
    "        \n",
    "        # Here I am drawing a bounding box on the frame for each detected object\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.probability > 0.40:\n",
    "                x = prediction.bounding_box.left * frame.shape[1]\n",
    "                y = prediction.bounding_box.top * frame.shape[0]\n",
    "                width = prediction.bounding_box.width * frame.shape[1]\n",
    "                height = prediction.bounding_box.height * frame.shape[0]\n",
    "                #Here I am adding the tag and prediction probability to be displayed along with the bounding box.\n",
    "                text = f\"{prediction.tag_name} ({prediction.probability*100:.1f}%)\"\n",
    "                if prediction.tag_name == \"bus\":\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+width), int(y+height)), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, text, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                elif prediction.tag_name == \"autorickshaw\":\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+width), int(y+height)), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, text, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                elif prediction.tag_name == \"bike\":\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+width), int(y+height)), (150, 0, 255), 2)\n",
    "                    cv2.putText(frame, text, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (150, 0, 255), 2)\n",
    "                elif prediction.tag_name == \"car\":\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+width), int(y+height)), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, text, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                elif prediction.tag_name == \"truck\":\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+width), int(y+height)), (255, 0, 255), 2)\n",
    "                    cv2.putText(frame, text, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "        #cv2.imwrite(output_filename, frame)\n",
    "        # Show the frame with bounding boxes\n",
    "        cv2.imshow('frame', frame)\n",
    "        output_path =  \"C:/Applications/Machine Learning/MDS-Data Science/mds-deakin/Object Detection using CustomVision/Dataset/video_images/labelled_images/\"\n",
    "        output_filename = output_path+\"image_{:04d}.jpg\".format(frame_count)\n",
    "        cv2.imwrite(output_filename, frame)\n",
    "    #cv2.imwrite(output_filename,frame_count )\n",
    "    #output.write(frame)\n",
    "    \n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "      # Increment the frame count\n",
    "    frame_count += 1\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "#output.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that I have all the labelled images along with the bounding boxes, I will iterate over each file and write them to a video. \n",
    "#I have set the frame rate to 5 frames per second\n",
    "\n",
    "frame_rate = 11.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "output = cv2.VideoWriter('./DataSet/traffic.mp4/output videos/output_video1.mp4', fourcc, frame_rate, (frame_width,frame_height))\n",
    "\n",
    "# Looping over the images in the directory and adding them to the video\n",
    "image_directory = './Dataset/video_images/labelled_images/'\n",
    "image_files = os.listdir(image_directory)\n",
    "for image_file in sorted(image_files):\n",
    "    # Reading the image\n",
    "    image_path = os.path.join(image_directory, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Resizing the image to the frame height and width\n",
    "    if image.shape[:2] != (frame_width,frame_height):\n",
    "        image = cv2.resize(image, (frame_width,frame_height))\n",
    "    \n",
    "    # Writing the image to the video\n",
    "    output.write(image)\n",
    "\n",
    "# Finally, I am releasing the video writer and closing the video file\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture('./DataSet/traffic.mp4/output videos/labelled_traffic7.mp4')\n",
    "\n",
    "# Get the original frame rate\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Set the new frame rate\n",
    "new_fps = 11  # Reduce the frame rate by half\n",
    "video.set(cv2.CAP_PROP_FPS, new_fps)\n",
    "\n",
    "# Define the output video codec and file name\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_file = './DataSet/traffic.mp4/output videos/output_video1.mp4'\n",
    "\n",
    "# Create a video writer object to write the processed video\n",
    "width, height = int(video.get(3)), int(video.get(4))\n",
    "writer = cv2.VideoWriter(output_file, fourcc, new_fps, (width, height))\n",
    "\n",
    "# Read and write each frame with the new frame rate\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    writer.write(frame)\n",
    "\n",
    "# Release the video objects\n",
    "video.release()\n",
    "writer.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
